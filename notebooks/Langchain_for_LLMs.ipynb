{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## How to inference Hugging Face models using Langchain"
      ],
      "metadata": {
        "id": "SP1xdra9-eUI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DG5xDpIp0IBL"
      },
      "outputs": [],
      "source": [
        "# install the necessay packages\n",
        "! pip -q install langchain langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# setting the Hugging Face Hub API token from user data\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = userdata.get('HFKey')"
      ],
      "metadata": {
        "id": "4Yx_5oFk0Saz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.llms import HuggingFaceEndpoint\n",
        "\n",
        "# prompt template for evaluating answers\n",
        "template = \"\"\"Evaluate the following question and check whether the given answer is correct or not.\n",
        "\n",
        "Question: {question}\n",
        "Answer: {answer}\n",
        "\n",
        "Provide the answer in a single word - YES or NO.\n",
        "\"\"\"\n",
        "\n",
        "# create a PromptTemplate instance with the defined template and input variables\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"question\", \"answer\"]\n",
        ")\n",
        "\n",
        "# initialize the Hugging Face model endpoint for inference\n",
        "model = HuggingFaceEndpoint(\n",
        "    repo_id=\"microsoft/Phi-3-mini-4k-instruct\"\n",
        ")"
      ],
      "metadata": {
        "id": "MmyLHydR0Tds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a70fd1e-1ad9-4541-807c-4f6b49c7e63b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a processing chain of the prompt and model\n",
        "chain = prompt | model\n",
        "\n",
        "question = \"What is 2+2?\"\n",
        "answer = \"5\"\n",
        "\n",
        "# invoke the chain with the question and answer, retrieving the result\n",
        "result = chain.invoke({\n",
        "    \"question\": f\"{question}\",\n",
        "    \"answer\": f\"{answer}\"\n",
        "})"
      ],
      "metadata": {
        "id": "YjuZj4Y11TQ9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "id": "sY_8QANL4UD6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75c0fee7-2c68-4a61-c687-bbf640bae41b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Solution: NO\n",
            "\n",
            "The correct answer to the question \"What is 2+2?\" is 4, not 5. Therefore, the given answer is incorrect.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Langchain with Pydantic Schema"
      ],
      "metadata": {
        "id": "j9Cz74hR9N74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Optional # for complex outputs\n",
        "from pydantic import Field, BaseModel\n",
        "from langchain.output_parsers import PydanticOutputParser"
      ],
      "metadata": {
        "id": "S5PXbwdW4UfN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EvaluationSchema(BaseModel):\n",
        "    # This sets the default value as the text provided.\n",
        "    # correct: str = Field(\"Check if the provided answer is correct or not - TRUE or FALSE.\")\n",
        "\n",
        "    correct: str = Field(description=\"Check if the provided answer is correct or not - TRUE or FALSE.\")"
      ],
      "metadata": {
        "id": "_Z_aiLRy4jq1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuestionEvaluator:\n",
        "    def __init__(self) -> None:\n",
        "\n",
        "        # intialize the prompt template for evaluating questions and answers\n",
        "        self.template = \"\"\"\n",
        "        Evaluate the following question and check whether the given answer is correct or not.\n",
        "\n",
        "        Question: {question}\n",
        "        Answer: {answer}\n",
        "\n",
        "        {format_instructions}\n",
        "        \"\"\"\n",
        "\n",
        "        # initialize the Hugging Face model endpoint for evaluation\n",
        "        self.model = HuggingFaceEndpoint(\n",
        "            repo_id=\"microsoft/Phi-3-mini-4k-instruct\"\n",
        "        )\n",
        "\n",
        "        # initialize a parser for output\n",
        "        self.parser = PydanticOutputParser(pydantic_object=EvaluationSchema)\n",
        "\n",
        "    def get_chain(self):\n",
        "\n",
        "        # retrieving format instructions from the parser\n",
        "        format_instructions = self.parser.get_format_instructions()\n",
        "\n",
        "        # creating a PromptTemplate instance with the evaluation template and input variables\n",
        "        prompt = PromptTemplate(\n",
        "            template=self.template,\n",
        "            input_variables=[\n",
        "                \"question\",\n",
        "                \"answer\"\n",
        "            ],\n",
        "            partial_variables={\n",
        "                \"format_instructions\": format_instructions\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # creating a processing chain that combines prompt, model, and parser\n",
        "        chain = prompt | self.model | self.parser\n",
        "\n",
        "        return chain\n",
        "\n",
        "    def envoke_chain(self, question, answer):\n",
        "\n",
        "        # load the processing chain\n",
        "        chain = self.get_chain()\n",
        "\n",
        "        # invoke the chain\n",
        "        result = chain.invoke({\n",
        "            \"question\": f\"{question}\",\n",
        "            \"answer\": f\"{answer}\"\n",
        "        })\n",
        "\n",
        "        return result"
      ],
      "metadata": {
        "id": "SNhocTuD5NRH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is 2+2?\"\n",
        "answer = \"5\"\n",
        "\n",
        "# create instance of QuestionEvaluator\n",
        "evaluator = QuestionEvaluator()\n",
        "\n",
        "# invoke the evaluation chain with the specified question and answer\n",
        "result = evaluator.envoke_chain(\n",
        "    question=question,\n",
        "    answer=answer\n",
        ").json()"
      ],
      "metadata": {
        "id": "K2F-a5Xi7kXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0136f8a5-c2e0-4cb3-c158-d057ff4665e9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWURf9h2m-r-",
        "outputId": "8e97b678-3351-4885-b946-8385214fea92"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"correct\":\"FALSE\"}\n"
          ]
        }
      ]
    }
  ]
}